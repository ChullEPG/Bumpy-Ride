{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10edac89-6281-42d0-b681-9782e8963d90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kinetic Model for \"A bumpy ride to electrification: High fidelity energy consumption estimates for paratransit vehicles in South Africa\"\n",
    "\n",
    "Welcome! This Jupyter Markdown file walks through the kinetic model used to estimate vehicle energy consumption from 1Hz GPS tracking data for  \"A bumpy ride to electrification: High fidelity energy consumption estimates for paratransit vehicles in South Africa\" - Hull, et al (2022) </br>\n",
    "• paper doi: </br>\n",
    "• data-in-brief doi: </br>\n",
    "• link to data repository: </br>\n",
    "\n",
    "Email addresses for questions, comments, concerns, suggestions, connections, etc: </br> mjbooysen@sun.ac.za </br> katherine.collett@eng.ox.ac.uk </br> christopher.hull@eng.ox.ac.uk\n",
    "\n",
    "\n",
    "Author: Christopher Hull </br>\n",
    "Date created: 10 June, 2022 </br>\n",
    "Date last updated: 10 June, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc540f84-91f8-4e25-b4ae-1dc855dacc1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download the Data\n",
    "To begin, download the data files from the 'Raw Data' folder at the Mendeley Data repository link above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e3b37-d36c-4025-89cd-8d7a8a209358",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import Packages\n",
    "Run the following cell to import all of the packages necessary for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a6101ca6-f4f6-4538-bd6a-6d6b8518f577",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import geopy.distance\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2c27e-3c8f-4f51-8209-b90d2dd2e8b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions to Load Data\n",
    "The \"get_raw_data\" function assumes the same file hierarchy as the data is stored in the Mendeley Data repository. Once you have downloaded the data, all you must do to load the data is provide a path from your current working directory to the 'path' string variable, and run the get_raw_data function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533bd56e-adf1-4177-9b23-1e050dfbbd90",
   "metadata": {},
   "source": [
    "Read file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10ace6dc-8d78-48eb-aac7-be9531281790",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "This function takes the filename of a GPS trip stored in a .csv file, and path to the file.\n",
    "\n",
    "It reads the file, cleans it, adds columns that are necessary for the kinetic model,\n",
    "and returns the file in a pandas dataframe\n",
    "'''\n",
    "\n",
    "def read_file(filename, path):\n",
    "\n",
    "    journey = pd.read_csv(path + \"/\" + filename)\n",
    "\n",
    "    ############################ Data cleaning #####################################\n",
    "\n",
    "    if 'Aatitude' in journey.columns:\n",
    "        journey['Altitude'] = journey['Aatitude']\n",
    "        journey.drop(columns = ['Aatitude'])\n",
    "\n",
    "    if 'GPS Speed' in journey.columns:\n",
    "        journey['Speed'] = journey['GPS Speed']\n",
    "        journey.drop(columns = ['GPS Speed'])\n",
    "\n",
    "    # Join date and time columns into one column\n",
    "    journey['DateTime'] = pd.to_datetime(journey['Date'] + journey['Time'], format = '%m/%d/%Y%H:%M:%S')\n",
    "\n",
    "    # Check if the time logger got stuck for a second, and correct if so\n",
    "    for i in range(len(journey) - 1):                                   \n",
    "         if journey['DateTime'][i] == journey['DateTime'][i + 1]:\n",
    "            journey['DateTime'][i + 1] += timedelta(seconds = 1)  \n",
    "            \n",
    "\n",
    "            \n",
    "    #######################################################################\n",
    "  \n",
    "    ############ Set up dataframe for energy consumption estimations ############\n",
    "\n",
    "    \n",
    "    # Convert speed in km/h to m/s \n",
    "    journey['Velocity'] = np.where(journey['Speed'] >= 0.5, journey['Speed']/3.6, 0) # \n",
    "    \n",
    "    \n",
    "   # for i in range(len(journey)): ### Observations less than 0.5 km/h are set to 0, due to GPS noise \n",
    "   #     if journey['Speed'][i] < 0.5:\n",
    "      #      journey['Velocity'][i] = 0\n",
    "\n",
    "    #Calculate elevation change\n",
    "    journey['ElevChange'] = np.where(abs(journey['Altitude'].shift(-1) - journey['Altitude']) >= 0.2, journey['Altitude'].shift(-1) - journey['Altitude'], 0)\n",
    "   # for i in range(len(journey)): # If measured elevation change < 0.2, then set to 0 due to GPS noise. \n",
    "    #    if abs(journey['ElevChange'][i]) < 0.2:\n",
    "     #       journey['ElevChange'][i] = 0 \n",
    "\n",
    "    # Calculate time between samples. Useful for kinetic model. \n",
    "    # This is needed because some samples are 1/2Hz. \n",
    "    journey['DeltaT'] = journey['DateTime'].shift(-1) - journey['DateTime']\n",
    "    journey.DeltaT = journey['DeltaT']/ np.timedelta64(1, 's') # Convert from timedelta to float\n",
    "    \n",
    "    # Calculate change in velocity between each timestep \n",
    "    journey['DeltaV'] = journey['Velocity'].shift(-1) - journey['Velocity']\n",
    "\n",
    "    # Calculate acceleration\n",
    "    journey['Acceleration'] = np.where(journey['DeltaT'] > 0, journey['DeltaV']/journey['DeltaT'], 0)\n",
    "\n",
    "    # Joins lat/lon Coords into one column, useful for getDist function\n",
    "    journey['Coordinates'] = list(zip(journey.Latitude, journey.Longitude)) \n",
    "\n",
    "    return journey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f91996-e1b3-4bcf-8bf2-c9ac318a8068",
   "metadata": {},
   "source": [
    "Get raw data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e02399d-7b03-4af2-8914-3361db345115",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "This function takes in a folder directory where the raw GPS data files are stored,\n",
    "reads the data files using the read_file function, \n",
    "and returns a nested dictionary containing all trip files, \n",
    "in the same hierarchy as the folders in which they are stored\n",
    "'''\n",
    "\n",
    "def get_raw_data(path):\n",
    "    raw_trips = {} # Dictionary to store all trips in as dataframes\n",
    "    \n",
    "    for root, dirs, files in os.walk(path, topdown = True): # Walk through directory\n",
    "        for file in files:    \n",
    "            if file.lower().endswith('.csv'): #make sure to only reading csv files and not auxiliary files in the directory\n",
    "                \n",
    "\n",
    "                this_trip = read_file(file,root)\n",
    "\n",
    "                route = root.split(os.sep)[1] # Get current route name\n",
    "                time_of_day = root.split(os.sep)[2] # Get current time of day\n",
    "                unit = os.path.splitext(file)[0] # Get unit\n",
    "                print(\"Reading:\", route,\"/\",time_of_day,\"/\",unit)\n",
    "\n",
    "                if route not in raw_trips: \n",
    "                    raw_trips[route] = {} # Create  dictionary for current route\n",
    "\n",
    "                if time_of_day not in raw_trips[route]:\n",
    "                    raw_trips[route][time_of_day] = {} # Create dictionary for current time of day within route\n",
    "\n",
    "                raw_trips[route][time_of_day][unit] = {} #Create dictionary entry to enter trip in \n",
    "                raw_trips[route][time_of_day][unit] = this_trip\n",
    "            \n",
    "    return raw_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4400674-9c44-4ccb-a182-d94119bf7b5c",
   "metadata": {},
   "source": [
    "• Each route and time of day combo is given its own nested dictionary to store data files in. </br>\n",
    "Thus, the dictionary structure in which the data is stored reflects the folder hierarchy. </br>\n",
    "\n",
    "• For example, there is a trip file UnitMain9.csv that was recorded in the morning on the route from Pniel - STB. Therefore it is stored in 'Pniel - STB'/'Morning'/'UnitMain_9.csv'. </br>\n",
    "Therefore, to access it in the raw_trips: raw_trips['Pniel - STB']['Morning']['UnitMain_9.csv'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cdff4-1711-45d0-8888-ab568b976d0e",
   "metadata": {},
   "source": [
    "• Now that we have the data loaded in, let's build the model...  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558abd4a-57cc-4ba1-a41b-7a0752f51ce7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions to Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e1345-a3e1-43ad-9ddd-33fb9fcc684a",
   "metadata": {},
   "source": [
    "Get slope angle and geodesic distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f20ccd6d-a270-4377-9748-938f0d32dbd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Inputs: dataframe with vehicle journey data\n",
    "\n",
    "Calculates distance between each successive pair of lat/lon coordinates\n",
    "(accounts for elevation difference)\n",
    "\n",
    "Calculates slope angle faced by vehicle at each timestamp\n",
    "\n",
    "'''\n",
    "def getDistSlope(journey):\n",
    "    Distance = np.zeros(len(journey))\n",
    "    Slope = np.zeros(len(journey))\n",
    "    l_route = journey.shape[0]\n",
    "\n",
    "    for i in range(0,l_route-1): \n",
    "      #  elev_change = journey['ElevChange'][i]\n",
    "        elev_change = journey['Altitude'][i + 1] - journey['Altitude'][i]\n",
    "        if abs(elev_change) < 0.2:\n",
    "            elev_change = 0\n",
    "        \n",
    "        dist_lateral = geopy.distance.geodesic(journey.Coordinates.iloc[i],  # (m) Lateral distance between two lat/lon coord pairs\n",
    "                                       journey.Coordinates.iloc[i+1]).m\n",
    "        dist_3d = np.sqrt(dist_lateral**2 + elev_change**2)  # (m) 3D Distance using pythogoras to account for elevation change\n",
    "        if i == 0:\n",
    "            Distance[i] = 0\n",
    "        else:\n",
    "            Distance[i] = dist_3d\n",
    "        if Distance[i] != 0 and elev_change != 0:\n",
    "            Slope[i] = np.arcsin(elev_change/dist_3d)\n",
    "    journey['Displacement_m'] = list(Distance) # Used for computing kWh/km \n",
    "    journey['slope_rad'] = list(Slope) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95133cad-959f-461e-a971-65a7a57553ce",
   "metadata": {},
   "source": [
    "Functions for retrieving environmental forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bf028a-f66c-425f-b702-ffca5ef07b9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Functions that calculate three environmental forces acting on the vehicle in (N)\n",
    "\n",
    "'''\n",
    "\n",
    "# Rolling Resistance (road friction) (N)\n",
    "def getRollingResistance(mass, c_rr, slope, vel, grav = 9.81): #c_rr is coeff of rolling resistance\n",
    "    rr = 0\n",
    "    if vel > 0.3:\n",
    "        rr = -mass * grav * c_rr * np.cos(slope)\n",
    "    return rr\n",
    " \n",
    "# Aerodynamic Drag Force (N)\n",
    "def getAerodynamicDrag(c_d, A, vel, rho = 1.184): # rho is air density 20C, c_d is air drag coeff\n",
    "    return -0.50 * rho * c_d * A * vel**2\n",
    "\n",
    "# Road Slope Force (N)\n",
    "def getRoadSlopeDrag(mass, slope, grav = 9.81):\n",
    "    return -mass * grav * np.sin(slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea9a0b-f97e-4233-9199-9decbe03d788",
   "metadata": {},
   "source": [
    "Drivecycle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba72fba-c725-4599-afbd-a56a0cfe34d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Drivecycle: \n",
    "    \"\"\"\n",
    "    Inputs: dataframe with journey info\n",
    "    \"\"\"\n",
    "    def __init__(self, journey): \n",
    "        self.displacement = journey.Displacement_m # m\n",
    "        self.velocity = journey.Velocity # m/s\n",
    "        self.acceleration = journey.Acceleration #m/s^2\n",
    "        self.slope = journey.slope_rad # rad\n",
    "        self.dt = journey.DeltaT # Time elapsed between each timestamp\n",
    "        self.dv = journey.DeltaV\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76adc3-ad3e-4186-b533-d43b2d32a91d",
   "metadata": {},
   "source": [
    "Vehicle class\n",
    "- Get energy expenditure function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14bb9eac-e60d-4ca0-99b5-d6926161f35d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    \"\"\"\n",
    "    Inputs: Physical parameters of vehicle for modeling energy consumption\n",
    "    Returns an array of vehicle energy consumption at each timestamp\n",
    "    \n",
    "    Default assumptions from \"A bumpy ride to electrification\":\n",
    "    mass = 3900 kg\n",
    "    cd = 0.36\n",
    "    crr = 0.02\n",
    "    A = 4 m^2\n",
    "    eff = 0.90\n",
    "    rgbeff = 0.65\n",
    "    p0 = 100 W\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mass = 3900, cd = 0.36, crr = 0.02, A = 4,\n",
    "                 eff = 0.9, rgbeff = 0.65, p0 = 100):\n",
    "\n",
    "        # Vehicle physical parameters\n",
    "        self.mass = mass # (kg) Total veh weight including payload\n",
    "        self.crr = crr # Rolling resistance coeff\n",
    "        self.cd = cd  # Air drag coeff\n",
    "        self.A = A # (m^2) Approximation of vehicle frontal area \n",
    "        self.eff = eff # Powertrain efficiency\n",
    "        self.rgbeff = rgbeff # Recuperative braking efficiency\n",
    "        self.p0 = p0 # (W) Constant power loss (to power auxiliary vehicle systems)\n",
    "\n",
    "        \n",
    "    # Computes energy expenditure from a Drivecycle object\n",
    "    def getEnergyExpenditure(self,cycle):\n",
    "        \n",
    "        v = cycle.velocity # (m/s) \n",
    "        s = cycle.slope # (rad)\n",
    "        a = cycle.acceleration # (m/s^2)\n",
    "        dt = cycle.dt # (s)\n",
    "        d = cycle.displacement # (m)\n",
    "        dv = cycle.dv # (m/s)\n",
    "            \n",
    "            \n",
    "        Er = [] # Total energy consumption (J), from battery if positive, to battery if negative (RGbrake)\n",
    "\n",
    "        \n",
    "                \n",
    "        for slope,vel,acc,delta_t, delta_v in zip(s,v,a,dt,dv):\n",
    "            \n",
    "            force, frr, fad, fsd = 0,0,0,0\n",
    "            \n",
    "            if vel != 0: #No drag if velocity = 0\n",
    "                frr = getRollingResistance(self.mass,self.crr, slope, vel) # (N)\n",
    "                fad = getAerodynamicDrag(self.cd, self.A, vel) # (N)\n",
    "                fsd = getRoadSlopeDrag(self.mass, slope) # (N)\n",
    "                \n",
    "            force = frr + fad + fsd # (N)\n",
    "            \n",
    "            exp_speed_delta = force * delta_t / self.mass # (N-s/kg)\n",
    "            \n",
    "            unexp_speed_delta = delta_v - exp_speed_delta # (m/s)\n",
    "            \n",
    "            try:\n",
    "                prop_brake_force = self.mass * unexp_speed_delta / delta_t # (kg * m/s)/(s) = (N)\n",
    "            \n",
    "                kinetic_power = prop_brake_force * vel # (N)*(m/s) = (W)\n",
    "                \n",
    "                propultion_work = kinetic_power * delta_t  # (W)*(s) = (J) \n",
    "                \n",
    "            except ZeroDivisionError:\n",
    "                prop_brake_force = 0\n",
    "                kinetic_power = 0\n",
    "                propultion_work = 0\n",
    "\n",
    "            Er.append(propultion_work) # (J)\n",
    "\n",
    "        ErP = [0.0]*len(Er)\n",
    "        ErB = [0.0]*len(Er)\n",
    "\n",
    "        for i in range(len(Er)):            \n",
    "            if Er[i] > 0: # Propulsion Energy \n",
    "                ErP[i] = Er[i]/self.eff # (J)\n",
    "                \n",
    "            elif Er[i] < 0: # Recuperated Energy (from regen braking system)\n",
    "                ErB[i]= Er[i]*self.rgbeff # (J)\n",
    "    \n",
    "    \n",
    "    \n",
    "        return ErP,ErB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66cc4f8-6bb9-4dfd-a85c-021832422610",
   "metadata": {},
   "source": [
    "Function to loop through raw trips and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b9b4396c-9c73-46d6-8a9a-85eac6e62fe4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Intakes dictionary of raw trip data\n",
    "Outputs dictionary of processed trip data, with energy expenditure computations\n",
    "'''\n",
    "def process_data(trip_dict, SUMO = False, mass = 3900, cd = 0.36, crr = 0.02, A = 4.0, eff = 0.90, rgbeff = 0.65, p0=100):\n",
    "    processed_trips = trip_dict #initialize dictionary of same structure\n",
    "    for route, v in trip_dict.items():\n",
    "        for time_of_day, v in trip_dict[route].items():\n",
    "            for unit,journey in trip_dict[route][time_of_day].items():\n",
    "                \n",
    "                print(\"Processing journey:\", route, time_of_day, unit) \n",
    "                minibus = Vehicle(mass = mass, cd = cd, crr = crr, A = A, eff = eff, rgbeff = rgbeff, p0 = p0)\n",
    "                \n",
    "                if SUMO:\n",
    "                    drvcycle = SUMO_Drivecycle(journey) # Create drivecycle object with trip data\n",
    "                else:\n",
    "                    getDistSlope(journey) # Augment journey dataframe with distance and slope columns\n",
    "                    drvcycle = Drivecycle(journey) # Create drivecycle object with trip data\n",
    "                \n",
    "                # Compute energy expenditure (with and without regenerative braking)\n",
    "                journey['Propultion Work (J)'],journey['Braking Work (J)'] = minibus.getEnergyExpenditure(drvcycle)\n",
    "                journey['Offload Work (J)'] = journey['DeltaT'] * p0 # (J)\n",
    "\n",
    "                journey['Energy Consumption (kWh)'] = (journey['Propultion Work (J)'] + journey['Braking Work (J)'] + journey['Offload Work (J)'])/3.6e6 # (kWh)                \n",
    "                \n",
    "                #Rename columns for clarity\n",
    "                journey['Displacement (m)'] = journey['Displacement_m']\n",
    "                journey['Slope Angle (rad)'] = journey['slope_rad']\n",
    "                \n",
    "            \n",
    "                #Drop duplicate and intermediate calculation columns to reduce clutter\n",
    "                journey = journey.drop(['Displacement_m', 'DeltaT', 'slope_rad', 'Velocity', 'DeltaV',\n",
    "                                       'Acceleration', 'Coordinates', 'DateTime', 'ElevChange'], axis = 1)\n",
    "                \n",
    "                #Insert processed journey into dictionary\n",
    "                processed_trips[route][time_of_day][unit] = journey\n",
    "                \n",
    "    return processed_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c86547-0266-4895-a98b-062ed75dbc9a",
   "metadata": {},
   "source": [
    "## Call read and process data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "080272ec-34d2-4f5e-a2a4-3788c5629ed5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: Pniel - STB / Morning / UnitMain_9\n",
      "Reading: Pniel - STB / Morning / Unit1_2\n",
      "Reading: Pniel - STB / Morning / UnitMain_10\n",
      "Reading: Pniel - STB / Midday / Unit3_5\n",
      "Reading: Pniel - STB / Midday / Unit1_6\n",
      "Reading: Pniel - STB / Midday / Unit4_4\n",
      "Reading: Pniel - STB / Midday / UnitMain_3\n",
      "Reading: Pniel - STB / Afternoon / UnitMain_11\n",
      "Reading: Pniel - STB / Afternoon / UnitMain_7\n",
      "Reading: Pniel - STB / Afternoon / Unit3_8\n",
      "Reading: KMNDI - STB / Morning / Unit3_3\n",
      "Reading: KMNDI - STB / Morning / Unit4_2\n",
      "Reading: KMNDI - STB / Morning / UnitOG_5\n",
      "Reading: KMNDI - STB / Morning / UnitMain_1\n",
      "Reading: KMNDI - STB / Midday / Unit1_10\n",
      "Reading: KMNDI - STB / Midday / Unit4_7\n",
      "Reading: KMNDI - STB / Midday / Unit2_9\n",
      "Reading: KMNDI - STB / Midday / UnitMain_6\n",
      "Reading: KMNDI - STB / Midday / Unit3_8\n",
      "Reading: KMNDI - STB / Afternoon / Unit3_13\n",
      "Reading: KMNDI - STB / Afternoon / Unit1_15\n",
      "Reading: KMNDI - STB / Afternoon / UnitMain_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/drvp7crx7qn3x5331z925m1c0000gt/T/ipykernel_22320/2401896306.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  journey['DateTime'][i + 1] += timedelta(seconds = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: KMNDI - STB / Afternoon / Unit4_12\n",
      "Reading: STB - KMNDI / Morning / Unit3_2\n",
      "Reading: STB - KMNDI / Morning / Unit1_3\n",
      "Reading: STB - KMNDI / Morning / UnitOG_4\n",
      "Reading: STB - KMNDI / Morning / UnitMain_1\n",
      "Reading: STB - KMNDI / Midday / Unit3_6\n",
      "Reading: STB - KMNDI / Midday / UnitMain_5\n",
      "Reading: STB - KMNDI / Midday / Unit1_9\n",
      "Reading: STB - KMNDI / Afternoon / Unit3_12\n",
      "Reading: STB - KMNDI / Afternoon / Unit1_14\n",
      "Reading: STB - KMNDI / Afternoon / UnitMain_10\n",
      "Reading: SW - STB / Morning / Unit4_3\n",
      "Reading: SW - STB / Morning / UnitOG_1\n",
      "Reading: SW - STB / Morning / UnitMain_2\n",
      "Reading: SW - STB / Midday / Unit1_7\n",
      "Reading: SW - STB / Midday / Unit3_6\n",
      "Reading: SW - STB / Midday / Unit4_5\n",
      "Reading: SW - STB / Midday / UnitMain_4\n",
      "Reading: SW - STB / Afternoon / Unit1_10\n",
      "Reading: SW - STB / Afternoon / Unit4_8\n",
      "Reading: SW - STB / Afternoon / Unit2_9\n",
      "Reading: STB - SW / Morning / Unit4_2\n",
      "Reading: STB - SW / Morning / UnitOG_3\n",
      "Reading: STB - SW / Morning / UnitMain_1\n",
      "Reading: STB - SW / Midday / Unit1_7\n",
      "Reading: STB - SW / Midday / Unit3_6\n",
      "Reading: STB - SW / Midday / Unit4_5\n",
      "Reading: STB - SW / Midday / UnitMain_4\n",
      "Reading: STB - SW / Afternoon / Unit1_11\n",
      "Reading: STB - SW / Afternoon / Unit2_10\n",
      "Reading: STB - SW / Afternoon / Unit4_8\n",
      "Reading: STB - SW / Afternoon / Unit3_9\n",
      "Reading: STB - Pniel / Morning / UnitMain_9\n",
      "Reading: STB - Pniel / Morning / UnitMain_10\n",
      "Reading: STB - Pniel / Morning / UnitMain_1\n",
      "Reading: STB - Pniel / Midday / Unit3_4\n",
      "Reading: STB - Pniel / Midday / Unit1_5\n",
      "Reading: STB - Pniel / Midday / Unit4_3\n",
      "Reading: STB - Pniel / Midday / UnitMain_2\n",
      "Reading: STB - Pniel / Afternoon / Unit3_7\n",
      "Reading: STB - Pniel / Afternoon / UnitMain_8\n",
      "Reading: STB - Pniel / Afternoon / UnitMain_6\n",
      "Processing journey: Pniel - STB Morning UnitMain_9\n",
      "Processing journey: Pniel - STB Morning Unit1_2\n",
      "Processing journey: Pniel - STB Morning UnitMain_10\n",
      "Processing journey: Pniel - STB Midday Unit3_5\n",
      "Processing journey: Pniel - STB Midday Unit1_6\n",
      "Processing journey: Pniel - STB Midday Unit4_4\n",
      "Processing journey: Pniel - STB Midday UnitMain_3\n",
      "Processing journey: Pniel - STB Afternoon UnitMain_11\n",
      "Processing journey: Pniel - STB Afternoon UnitMain_7\n",
      "Processing journey: Pniel - STB Afternoon Unit3_8\n",
      "Processing journey: KMNDI - STB Morning Unit3_3\n",
      "Processing journey: KMNDI - STB Morning Unit4_2\n",
      "Processing journey: KMNDI - STB Morning UnitOG_5\n",
      "Processing journey: KMNDI - STB Morning UnitMain_1\n",
      "Processing journey: KMNDI - STB Midday Unit1_10\n",
      "Processing journey: KMNDI - STB Midday Unit4_7\n",
      "Processing journey: KMNDI - STB Midday Unit2_9\n",
      "Processing journey: KMNDI - STB Midday UnitMain_6\n",
      "Processing journey: KMNDI - STB Midday Unit3_8\n",
      "Processing journey: KMNDI - STB Afternoon Unit3_13\n",
      "Processing journey: KMNDI - STB Afternoon Unit1_15\n",
      "Processing journey: KMNDI - STB Afternoon UnitMain_11\n",
      "Processing journey: KMNDI - STB Afternoon Unit4_12\n",
      "Processing journey: STB - KMNDI Morning Unit3_2\n",
      "Processing journey: STB - KMNDI Morning Unit1_3\n",
      "Processing journey: STB - KMNDI Morning UnitOG_4\n",
      "Processing journey: STB - KMNDI Morning UnitMain_1\n",
      "Processing journey: STB - KMNDI Midday Unit3_6\n",
      "Processing journey: STB - KMNDI Midday UnitMain_5\n",
      "Processing journey: STB - KMNDI Midday Unit1_9\n",
      "Processing journey: STB - KMNDI Afternoon Unit3_12\n",
      "Processing journey: STB - KMNDI Afternoon Unit1_14\n",
      "Processing journey: STB - KMNDI Afternoon UnitMain_10\n",
      "Processing journey: SW - STB Morning Unit4_3\n",
      "Processing journey: SW - STB Morning UnitOG_1\n",
      "Processing journey: SW - STB Morning UnitMain_2\n",
      "Processing journey: SW - STB Midday Unit1_7\n",
      "Processing journey: SW - STB Midday Unit3_6\n",
      "Processing journey: SW - STB Midday Unit4_5\n",
      "Processing journey: SW - STB Midday UnitMain_4\n",
      "Processing journey: SW - STB Afternoon Unit1_10\n",
      "Processing journey: SW - STB Afternoon Unit4_8\n",
      "Processing journey: SW - STB Afternoon Unit2_9\n",
      "Processing journey: STB - SW Morning Unit4_2\n",
      "Processing journey: STB - SW Morning UnitOG_3\n",
      "Processing journey: STB - SW Morning UnitMain_1\n",
      "Processing journey: STB - SW Midday Unit1_7\n",
      "Processing journey: STB - SW Midday Unit3_6\n",
      "Processing journey: STB - SW Midday Unit4_5\n",
      "Processing journey: STB - SW Midday UnitMain_4\n",
      "Processing journey: STB - SW Afternoon Unit1_11\n",
      "Processing journey: STB - SW Afternoon Unit2_10\n",
      "Processing journey: STB - SW Afternoon Unit4_8\n",
      "Processing journey: STB - SW Afternoon Unit3_9\n",
      "Processing journey: STB - Pniel Morning UnitMain_9\n",
      "Processing journey: STB - Pniel Morning UnitMain_10\n",
      "Processing journey: STB - Pniel Morning UnitMain_1\n",
      "Processing journey: STB - Pniel Midday Unit3_4\n",
      "Processing journey: STB - Pniel Midday Unit1_5\n",
      "Processing journey: STB - Pniel Midday Unit4_3\n",
      "Processing journey: STB - Pniel Midday UnitMain_2\n",
      "Processing journey: STB - Pniel Afternoon Unit3_7\n",
      "Processing journey: STB - Pniel Afternoon UnitMain_8\n",
      "Processing journey: STB - Pniel Afternoon UnitMain_6\n"
     ]
    }
   ],
   "source": [
    "path = \"DataCollection/\"\n",
    "raw_trips = get_raw_data(path)\n",
    "processed_trips = process_data(raw_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceafe4c-16ec-4ee5-9732-aece9cff24fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## How to analyze`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961050cf-f7af-4902-9a06-05c64917c3ab",
   "metadata": {},
   "source": [
    "Now you have all of the trips stored in the 'processed_trips' dictionary \n",
    "To loop through this dictionary and perform analysis on the trips you can use the for loops in the following block of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5c1840b-f37e-4bca-9ff3-435e25391df1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Morning Recorded on:  UnitMain_9\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Morning Recorded on:  Unit1_2\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Morning Recorded on:  UnitMain_10\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Afternoon Recorded on:  Unit3_5\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Afternoon Recorded on:  Unit1_6\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Afternoon Recorded on:  Unit4_4\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Afternoon Recorded on:  UnitMain_3\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Evening Recorded on:  UnitMain_11\n",
      "Here lies the dataframe for a trip taken between:  Pniel - STB \n",
      " During the:  Evening Recorded on:  UnitMain_7\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Morning Recorded on:  Unit3_3\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Morning Recorded on:  Unit4_2\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Morning Recorded on:  UnitOG_5\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Morning Recorded on:  UnitMain_1\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Afternoon Recorded on:  Unit1_10\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Afternoon Recorded on:  Unit4_7\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Afternoon Recorded on:  Unit2_9\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Afternoon Recorded on:  UnitMain_6\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Afternoon Recorded on:  Unit3_8\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Evening Recorded on:  Unit3_13\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Evening Recorded on:  UnitMain_11\n",
      "Here lies the dataframe for a trip taken between:  KMNDI - STB \n",
      " During the:  Evening Recorded on:  Unit4_12\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Morning Recorded on:  Unit3_2\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Morning Recorded on:  Unit1_3\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Morning Recorded on:  UnitOG_4\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Morning Recorded on:  UnitMain_1\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Afternoon Recorded on:  Unit3_6\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Afternoon Recorded on:  UnitMain_5\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Afternoon Recorded on:  Unit1_9\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Evening Recorded on:  Unit3_12\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Evening Recorded on:  Unit1_14\n",
      "Here lies the dataframe for a trip taken between:  STB - KMNDI \n",
      " During the:  Evening Recorded on:  UnitMain_10\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Morning Recorded on:  Unit4_3\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Morning Recorded on:  UnitOG_1\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Morning Recorded on:  UnitMain_2\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Afternoon Recorded on:  Unit1_7\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Afternoon Recorded on:  Unit3_6\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Afternoon Recorded on:  Unit4_5\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Afternoon Recorded on:  UnitMain_4\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Evening Recorded on:  Unit1_10\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Evening Recorded on:  Unit4_8\n",
      "Here lies the dataframe for a trip taken between:  SW - STB \n",
      " During the:  Evening Recorded on:  Unit2_9\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Morning Recorded on:  Unit4_2\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Morning Recorded on:  UnitOG_3\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Morning Recorded on:  UnitMain_1\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Afternoon Recorded on:  Unit1_7\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Afternoon Recorded on:  Unit3_6\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Afternoon Recorded on:  Unit4_5\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Afternoon Recorded on:  UnitMain_4\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Evening Recorded on:  Unit1_11\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Evening Recorded on:  Unit2_10\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Evening Recorded on:  Unit4_8\n",
      "Here lies the dataframe for a trip taken between:  STB - SW \n",
      " During the:  Evening Recorded on:  Unit3_9\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Morning Recorded on:  UnitMain_9\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Morning Recorded on:  UnitMain_10\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Morning Recorded on:  UnitMain_1\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Afternoon Recorded on:  Unit3_4\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Afternoon Recorded on:  Unit1_5\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Afternoon Recorded on:  Unit4_3\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Afternoon Recorded on:  UnitMain_2\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Evening Recorded on:  Unit3_7\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Evening Recorded on:  UnitMain_8\n",
      "Here lies the dataframe for a trip taken between:  STB - Pniel \n",
      " During the:  Evening Recorded on:  UnitMain_6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for route, route_subdict in processed_trips.items():\n",
    "    for time_of_day, route_tod_subdict in processed_trips[route].items():\n",
    "        for unit, journey_df in processed_trips[route][time_of_day].items():\n",
    "            print(\"Here lies the dataframe for a trip taken on/during/recorded with: \", route, \"/\", time_of_day, \"/\", unit, \"\\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9248604-7115-4dd0-8d8a-deb530d1241b",
   "metadata": {},
   "source": [
    "Example usage of this loop to perform summary statistics on energy consumptions for all trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "81abf9cb-dd89-4b26-baa0-0ae83f321395",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pniel - STB Afternoon Unit3_8\n",
      "KMNDI - STB Afternoon Unit1_15\n",
      "       Energy Consumption (kWh)\n",
      "count                     64.00\n",
      "mean                       0.39\n",
      "std                        0.05\n",
      "min                        0.31\n",
      "25%                        0.35\n",
      "50%                        0.38\n",
      "75%                        0.42\n",
      "max                        0.51\n"
     ]
    }
   ],
   "source": [
    "energy_consumption = []\n",
    "routes = []\n",
    "tod = []\n",
    "\n",
    "for route, route_subdict in processed_trips.items():\n",
    "    for time_of_day, route_tod_subdict in processed_trips[route].items():\n",
    "        for unit, journey_df in processed_trips[route][time_of_day].items():\n",
    "            energy_consumption.append(journey_df['Energy Consumption (kWh)'].sum()/(journey_df['Displacement (m)'].sum()/1e3))\n",
    "            tod.append(time_of_day)\n",
    "            routes.append(route)\n",
    "            if journey_df.Speed[0] > 50:\n",
    "                print(route, time_of_day, unit)\n",
    "            \n",
    "            \n",
    "summ_df = pd.DataFrame({'Energy Consumption (kWh)': pd.Series(energy_consumption), \n",
    "              'Time of Day': pd.Series(tod), \n",
    "              'Route': pd.Series(route)})\n",
    "\n",
    "print(round(summ_df.describe(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df62a5-accd-4fb8-8cdd-1bc39e3fd1f3",
   "metadata": {},
   "source": [
    "Write Files to \"Processed Data\" Folder (must create a Processed Data folder or equivalent to store the data in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2726d09e-05fd-43a7-b32f-828945af1875",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_processed_files(folder, all_journeys):\n",
    "    for route, x in all_journeys.items():\n",
    "        for tod, m in all_journeys[route].items():\n",
    "            for unit, journey in all_journeys[route][tod].items():\n",
    "                filename = folder + \"/\" + route + \"/\" + tod + \"/\" + unit + \".csv\"\n",
    "                output_file = Path(filename)\n",
    "                output_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "                journey.to_csv(filename)\n",
    "\n",
    "\n",
    "output_folder = \"Processed Data\"\n",
    "write_processed_files(output_folder, processed_trips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
